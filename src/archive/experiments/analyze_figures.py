"""Analyze all figures and data to identify issues."""

import pickle
import numpy as np
from pathlib import Path

results_dir = Path("results")

print("=" * 70)
print("FIGURE ANALYSIS REPORT")
print("=" * 70)

# =============================================================================
# 1. SCORE DISTRIBUTIONS (score_distributions.png)
# =============================================================================
print("\n" + "=" * 70)
print("1. SCORE DISTRIBUTIONS FIGURE")
print("=" * 70)

try:
    geo = pickle.load(open(results_dir / "geometry_study_results.pkl", "rb"))
    print("\nData source: geometry_study_results.pkl")
    print(f"System sizes: {geo['system_sizes']}")
    
    issues = []
    for L in geo['system_sizes']:
        print(f"\n  L={L}:")
        for cls in geo['score_distributions'][L]:
            d = geo['score_distributions'][L][cls]
            mean = d['mean']
            std = d['std']
            n = len(d['scores'])
            print(f"    {cls:12s}: mean={mean:+.4f}, std={std:.4f}, n={n}")
            
            # Check for issues
            if n < 20:
                issues.append(f"L={L}, {cls}: Only {n} samples (need 20+)")
            if std < 0.001:
                issues.append(f"L={L}, {cls}: Zero/tiny std ({std:.6f})")
    
    if issues:
        print("\n  ⚠️ ISSUES FOUND:")
        for iss in issues:
            print(f"    - {iss}")
    else:
        print("\n  ✓ No major data issues")
        
except Exception as e:
    print(f"ERROR: {e}")

# =============================================================================
# 2. TIME DEPENDENCE (time_dependence_study.png)
# =============================================================================
print("\n" + "=" * 70)
print("2. TIME DEPENDENCE FIGURE")
print("=" * 70)

# This was generated on-the-fly, check if results exist
print("\nNote: This figure was generated by running time_dependence_study.py")
print("It runs new simulations each time (not from saved pickle)")
print("The figure exists but may need regeneration with better parameters")

# =============================================================================
# 3. UNIVERSALITY DISTANCE (universality_distance_main.png)
# =============================================================================
print("\n" + "=" * 70)
print("3. UNIVERSALITY DISTANCE FIGURE")
print("=" * 70)

try:
    ud = pickle.load(open(results_dir / "universality_distance_results.pkl", "rb"))
    print("\nData source: universality_distance_results.pkl")
    print(f"Keys: {list(ud.keys())}")
    
    if 'distance' in ud:
        d = ud['distance']
        kappa = np.array(d['kappa'])
        D_ML = np.array(d['D_ML'])
        D_ML_std = np.array(d.get('D_ML_std', [0]*len(kappa)))
        
        print(f"\nKappa values: {len(kappa)} points")
        print(f"  Range: {min(kappa):.3f} to {max(kappa):.3f}")
        print(f"D_ML values:")
        print(f"  Range: {min(D_ML):.4f} to {max(D_ML):.4f}")
        print(f"  Mean error: {np.mean(D_ML_std):.4f}")
        
        # Check for issues
        issues = []
        if len(kappa) < 10:
            issues.append(f"Only {len(kappa)} kappa points (need 15+)")
        if max(D_ML) < 0.5:
            issues.append(f"D_ML doesn't saturate (max={max(D_ML):.3f})")
        if min(D_ML) > 0.1:
            issues.append(f"D_ML doesn't start near 0 (min={min(D_ML):.3f})")
            
    if 'fit' in ud:
        f = ud['fit']
        print(f"\nFit parameters:")
        print(f"  kappa_c = {f.get('kappa_c', 'N/A')}")
        print(f"  gamma = {f.get('gamma', 'N/A')}")
        print(f"  R² = {f.get('r_squared', 'N/A')}")
        
    if issues:
        print("\n  ⚠️ ISSUES FOUND:")
        for iss in issues:
            print(f"    - {iss}")
    else:
        print("\n  ✓ No major data issues")
        
except Exception as e:
    print(f"ERROR: {e}")

# =============================================================================
# 4. EXPONENT VS ML (exponent_vs_ml_main.png)
# =============================================================================
print("\n" + "=" * 70)
print("4. EXPONENT VS ML FIGURE")
print("=" * 70)

try:
    exp = pickle.load(open(results_dir / "exponent_comparison_results.pkl", "rb"))
    print("\nData source: exponent_comparison_results.pkl")
    print(f"Keys: {list(exp.keys())}")
except Exception as e:
    print(f"ERROR: {e}")

# =============================================================================
# 5. BOOTSTRAP DIAGNOSTICS (bootstrap_diagnostics.png)
# =============================================================================
print("\n" + "=" * 70)
print("5. BOOTSTRAP DIAGNOSTICS FIGURE")
print("=" * 70)

try:
    bs = pickle.load(open(results_dir / "bootstrap_results.pkl", "rb"))
    print("\nData source: bootstrap_results.pkl")
    print(f"Keys: {list(bs.keys())}")
    
    if 'kappa_c_samples' in bs:
        kc = np.array(bs['kappa_c_samples'])
        print(f"\nkappa_c bootstrap: n={len(kc)}, mean={np.mean(kc):.4f}, std={np.std(kc):.4f}")
    if 'gamma_samples' in bs:
        g = np.array(bs['gamma_samples'])
        print(f"gamma bootstrap: n={len(g)}, mean={np.mean(g):.4f}, std={np.std(g):.4f}")
except Exception as e:
    print(f"ERROR: {e}")

print("\n" + "=" * 70)
print("SUMMARY: FIGURES NEEDING REGENERATION")
print("=" * 70)
print("""
1. score_distributions.png - CHECK DATA QUALITY
   - Verify class separation is visible
   - Ensure histograms don't overlap badly
   
2. time_dependence_study.png - REGENERATE
   - Was generated with only 10 samples
   - Should show convergence of known classes
   - Unknown class should stay anomalous

3. universality_distance_main.png - CHECK FIT QUALITY
   - Verify smooth transition from 0 to 1
   - Confirm crossover point is visible

4. exponent_vs_ml_main.png - CHECK COMPARISON
   - SNR comparison should favor D_ML

5. bootstrap_diagnostics.png - LIKELY OK
   - Standard diagnostic histograms
""")
